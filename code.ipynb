{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01c55793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import math\n",
    "import random\n",
    "import math\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib as plt\n",
    "import scipy as sp\n",
    "import scipy.sparse as sparse\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import subprocess as sproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3af563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________\n",
    "# CONSTANTS\n",
    "\n",
    "TRANSFORMATIONS = [\"identity\", \"modularity\", \"Laplacian\", \"signless_Laplacian\", \"general_Zagreb\", \"Seidel\", \"sum_connectivity\", \"transition_rw\", \"Bethe_Hessian\", \"FLCM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2359c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________\n",
    "# SPECTRAL GRAPH FORGE\n",
    "\n",
    "def SGF(G, transformation = \"modularity\", alpha = 0.8, normalization_type = \"truncate\", k = 6):\n",
    "\n",
    "    #____________________________________________\n",
    "    # INPUT MATRIX\n",
    "\n",
    "    # Setting up basic parameters\n",
    "    A = nx.adjacency_matrix(G).toarray()\n",
    "    n = len(A)\n",
    "    degrees = [G.degree[node] for node in G.nodes()]\n",
    "    M = np.zeros((n, n))\n",
    "\n",
    "    # identity transformation\n",
    "    if transformation == \"identity\":\n",
    "        M = A\n",
    "\n",
    "    # modularity transformation\n",
    "    elif transformation == \"modularity\":\n",
    "        m = sum(degrees) / 2\n",
    "        B = A - np.outer(degrees, degrees) / (2 * m)\n",
    "        M = B\n",
    "\n",
    "    # laplacian transformation\n",
    "    elif transformation == \"Laplacian\":\n",
    "        D = np.diag(degrees)\n",
    "        L = D - A\n",
    "        M = L\n",
    "\n",
    "    # signless laplacian transformation\n",
    "    elif transformation == \"signless_Laplacian\":\n",
    "        D = np.diag(degrees)\n",
    "        L_signless = D + A\n",
    "        M = L_signless\n",
    "\n",
    "    # Normalized Laplacian transformation\n",
    "    elif transformation == \"normalized_Laplacian\": # TODO DELETE THIS THING\n",
    "        D_inv_sqrt = np.diag(1.0 / np.sqrt(np.sum(A, axis=1)))\n",
    "        L_norm = np.eye(A.shape[0]) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "        M = L_norm\n",
    "\n",
    "    # General Zagreb transformation\n",
    "    elif transformation == \"general_Zagreb\":\n",
    "        D = np.diag(degrees)\n",
    "        GZ = pow(D,3) + A\n",
    "        M = GZ\n",
    "\n",
    "    # Seidel transformation\n",
    "    elif transformation == \"Seidel\":\n",
    "        A_complement = np.ones((n, n)) - A - np.eye(n)\n",
    "        S = A - A_complement\n",
    "        M = S\n",
    "\n",
    "    # Sum connectivity transformation\n",
    "    elif transformation == \"sum_connectivity\":\n",
    "        SC = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if A[i][j] == 1:\n",
    "                    SC[i][j] = A[i][j] * (1 / math.sqrt((degrees[i] * degrees[j])))\n",
    "        M = SC\n",
    "\n",
    "    # Transition Random Walk transformation\n",
    "    elif transformation == \"transition_rw\":\n",
    "        D = np.diag(degrees)\n",
    "        P = np.linalg.inv(D) @ A\n",
    "        M = P\n",
    "\n",
    "    # Bethe-Hessian transformation\n",
    "    elif transformation == \"Bethe_Hessian\":\n",
    "        # Computing the non-backtracking matrix\n",
    "        Gdirect = G.to_directed()\n",
    "        S = np.zeros((len(Gdirect.edges),len(G.nodes)))\n",
    "        T = np.zeros((len(G.nodes),len(Gdirect.edges)))\n",
    "        for i,a in enumerate(Gdirect.edges):\n",
    "            for j,b in enumerate(G.nodes):\n",
    "                if a [ 1 ] == b:\n",
    "                    S[i,j]=1\n",
    "                if a [ 0 ] == b :\n",
    "                    T[j,i] = 1\n",
    "        tau = np.zeros((len(Gdirect.edges),len(Gdirect.edges)))\n",
    "        for i,a in enumerate(Gdirect.edges):\n",
    "            for j,b in enumerate(Gdirect.edges):\n",
    "                if a[0]==b[1] and a[1]==b[0]:\n",
    "                    tau[i][j] = 1\n",
    "        B = S@T - tau\n",
    "        # Computing the Bethe-Hessian matrix\n",
    "        D = np.diag(degrees)\n",
    "        I = np.eye(n, n)\n",
    "        rho = max(abs(np.linalg.eigvals(B)))\n",
    "        # rho = np.mean(degrees) # alternative way to compute rho\n",
    "        r = pow(rho, 1/2)\n",
    "        # r = sum(d**2 for v, d in nx.degree(G)) / sum(d for v, d in nx.degree(G)) - 1 # alternative way to compute r\n",
    "        H = (pow(r,2) - 1) * I - r * A + D\n",
    "        M = H\n",
    "\n",
    "    elif transformation == \"FLCM\":\n",
    "        s = np.sum((np.sum(A, axis=1)) ** 2)\n",
    "        D = np.diag(degrees)\n",
    "        I = np.eye(n, n)\n",
    "        T = A - (1/3)*(np.outer(degrees, degrees) / (2*s)) + (1/3)*I\n",
    "        M = T\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid transformation\")\n",
    "\n",
    "    #____________________________________________\n",
    "    # LOW RANK ALPHA APPROXIMATION\n",
    "    \n",
    "    # Procedure for Bethe-Hessian transformation\n",
    "    if transformation == \"What I wanted from Bethe Hessian\":\n",
    "        # Computation of eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(M)\n",
    "        eigenvectors = eigenvectors.T\n",
    "\n",
    "        # sorting the eigenvectors, eigenvalues\n",
    "        paired_sorted_list = sorted(zip(eigenvalues, eigenvectors), key=lambda x: x[0])\n",
    "        eigenvalues_sorted, eigenvectors_sorted = zip(*paired_sorted_list)\n",
    "\n",
    "        # Computation of M_tilde\n",
    "        M_tilde = np.zeros((eigenvectors_sorted[0].shape[0], eigenvectors_sorted[0].shape[0]))\n",
    "        for i in range(math.ceil(alpha * len(eigenvalues) * 0.5)):\n",
    "            contribution = eigenvalues_sorted[i] * np.outer(eigenvectors_sorted[i], eigenvectors_sorted[i])\n",
    "            M_tilde += contribution\n",
    "            if i == 0:\n",
    "                pass\n",
    "            else:\n",
    "                contribution = eigenvalues_sorted[-i] * np.outer(eigenvectors_sorted[-i], eigenvectors_sorted[-i])\n",
    "                M_tilde += contribution\n",
    "\n",
    "    # Procedure for other transformations\n",
    "    else:\n",
    "        # Computation of eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eigh(M)\n",
    "        eigenvectors = eigenvectors.T\n",
    "\n",
    "        # sorting the eigenvectors, eigenvalues\n",
    "        paired_sorted_list = sorted(zip(eigenvalues, eigenvectors), key=lambda x: abs(x[0]), reverse=True)\n",
    "        eigenvalues_sorted, eigenvectors_sorted = zip(*paired_sorted_list)\n",
    "\n",
    "        # Computation of M_tilde\n",
    "        M_tilde = np.zeros((eigenvectors_sorted[0].shape[0], eigenvectors_sorted[0].shape[0]))\n",
    "        for i in range(math.ceil(alpha * len(eigenvalues))):\n",
    "            contribution = eigenvalues_sorted[i] * np.outer(eigenvectors_sorted[i], eigenvectors_sorted[i])\n",
    "            M_tilde += contribution\n",
    "\n",
    "    #____________________________________________\n",
    "    # BACK TRANSFORMATION\n",
    "        \n",
    "    # Computation of A_tilde\n",
    "    A_tilde = np.zeros((n, n))\n",
    "    if transformation == \"identity\":\n",
    "        A_tilde = M_tilde\n",
    "    elif transformation == \"modularity\":\n",
    "        A_tilde = M_tilde + np.outer(degrees, degrees) / (2 * m)\n",
    "    elif transformation == \"Laplacian\":\n",
    "        A_tilde = D - M_tilde\n",
    "    elif transformation == \"signless_Laplacian\":\n",
    "        A_tilde = M_tilde - D\n",
    "    elif transformation == \"normalized_Laplacian\":\n",
    "        D_sqrt = np.diag(np.sqrt(np.sum(A, axis=1)))\n",
    "        A_tilde = D_sqrt @ (np.eye(A.shape[0]) - M_tilde) @ D_sqrt\n",
    "    elif transformation == \"general_Zagreb\":\n",
    "        A_tilde = M_tilde - pow(D,3)\n",
    "    elif transformation == \"Seidel\":\n",
    "        A_tilde = M_tilde + A_complement\n",
    "    elif transformation == \"sum_connectivity\":\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if A[i][j] == 1:\n",
    "                    A_tilde[i][j] = M_tilde[i][j] * math.sqrt((degrees[i] * degrees[j]))\n",
    "    elif transformation == \"transition_rw\":\n",
    "        A_tilde = D @ M_tilde\n",
    "    elif transformation == \"Bethe_Hessian\":\n",
    "        A_tilde = ((r**2 - 1) * I - M_tilde + D) * (1 / r)\n",
    "    elif transformation == \"FLCM\":\n",
    "        A_tilde = M_tilde + (1/3)*(np.outer(degrees, degrees) / (2*s)) - (1/3)*I\n",
    "\n",
    "    #____________________________________________\n",
    "    # NORMALIZATION\n",
    "\n",
    "    # logistic\n",
    "    A_dots = np.zeros((n, n))\n",
    "    if normalization_type == \"logistic\":\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                A_dots[i][j] = 1 / (1 + math.exp((0.5 - A_tilde[i][j])*k))\n",
    "\n",
    "    # truncation\n",
    "    elif normalization_type == \"truncate\":\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if A_tilde[i][j] < 0:\n",
    "                    A_dots[i][j] = 0\n",
    "                elif A_tilde[i][j] > 1:\n",
    "                    A_dots[i][j] = 1\n",
    "                else:\n",
    "                    A_dots[i][j] = A_tilde[i][j]\n",
    "\n",
    "    # scaling\n",
    "    elif normalization_type == \"scale\":\n",
    "        A_tilde_flattened = A_tilde.flatten()\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                A_dots[i][j] = (A_tilde[i][j] - min(A_tilde_flattened)) / (max(A_tilde_flattened) - min(A_tilde_flattened))\n",
    "    \n",
    "    #____________________________________________\n",
    "    # ADJACENCY MATRIX GENERATION\n",
    "    \n",
    "    # Bernoulli sampling\n",
    "    A_prime = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            u = random.uniform(0, 1)\n",
    "            if u < A_dots[i][j]:\n",
    "                A_prime[i][j] = 1\n",
    "                A_prime[j][i] = 1\n",
    "            else:\n",
    "                A_prime[i][j] = 0\n",
    "                A_prime[j][i] = 0\n",
    "            if i == j:\n",
    "                A_prime[i][j] = 0\n",
    "\n",
    "    W = nx.from_numpy_array(A_prime)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f491ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________\n",
    "# EDIT DISTANCE\n",
    "\n",
    "def edit_distance(A1,A2, k = 10):\n",
    "    dist = np.abs((A1-A2)).sum() / 2\n",
    "    return 1 - k / (k + dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e08148ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________\n",
    "# COMPARABILITY MEASURE COMPUTATION\n",
    "\n",
    "# Euclidean distance from point (1,1,0)\n",
    "def comparability_measure(avg_clustering, modularity_communities, edit_distance):\n",
    "    return np.sqrt((avg_clustering - 1)**2 + (modularity_communities - 1)**2 + (edit_distance - 1)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a92770d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________\n",
    "# STATISTICS COMPUTATION\n",
    "\n",
    "def chart_data(graphs, alpha_nums, sample_size = 5):\n",
    "    count = 0\n",
    "    alphas = {v: {} for v in alpha_nums}\n",
    "    for alpha in tqdm(list(alphas.keys())):\n",
    "        transformation_dict = {}\n",
    "        for transformation in TRANSFORMATIONS:\n",
    "            transformation_dict[transformation] = {}\n",
    "        for transformation in list(transformation_dict.keys()):\n",
    "            measure_dict = {\n",
    "                \"avg_clustering_ratio_obs\": [],\n",
    "                \"modularity_communities_ratio_obs\": [],\n",
    "                \"edit_distance\": [], #ith value corresponds to ith graph (average of sample_size runs)\n",
    "                \"comparability_measure\": [] #ith value corresponds to ith graph (average of sample_size runs)\n",
    "            }\n",
    "            for graph in tqdm(graphs): \n",
    "                graph_avg_clusterings = []\n",
    "                graph_modularities = []\n",
    "                distances = []\n",
    "                comparabilities = []\n",
    "                for i in range(sample_size):\n",
    "                    count += 1\n",
    "                    w = SGF(graph, transformation, alpha)\n",
    "                    avg_cls =nx.average_clustering(w)/ nx.average_clustering(graph)\n",
    "                    mod = len(nx.community.greedy_modularity_communities(w)) / len(nx.community.greedy_modularity_communities(graph))\n",
    "                    dist = edit_distance(nx.adjacency_matrix(graph), nx.adjacency_matrix(w))\n",
    "                    comparability = comparability_measure(avg_cls, mod, dist)\n",
    "                    graph_avg_clusterings.append(avg_cls)\n",
    "                    graph_modularities.append(mod)\n",
    "                    distances.append(dist)\n",
    "                    comparabilities.append(comparability)\n",
    "                measure_dict[\"avg_clustering_ratio_obs\"].extend(graph_avg_clusterings)\n",
    "                measure_dict[\"modularity_communities_ratio_obs\"].extend(graph_modularities)\n",
    "                avg_distances = np.mean(distances)\n",
    "                avg_comparabilities = np.mean(comparabilities)\n",
    "                measure_dict[\"edit_distance\"].append(avg_distances)\n",
    "                measure_dict[\"comparability_measure\"].append(avg_comparabilities)\n",
    "                \n",
    "            transformation_dict[transformation] = measure_dict\n",
    "            \n",
    "        alphas[alpha] = transformation_dict\n",
    "        \n",
    "    return alphas, count\n",
    "\n",
    "#____________________________________________\n",
    "# BOXPLOTS OF AVG CLUSTERING RATIO AND MODULARITY COMMUNITIES RATIO\n",
    "\n",
    "def boxplots(chart_data):\n",
    "    for metric in [\"avg_clustering_ratio_obs\", \"modularity_communities_ratio_obs\"]:\n",
    "        for alpha in list(chart_data.keys()):\n",
    "            # df = pd.DataFrame(alphas[alpha])\n",
    "            df = pd.DataFrame(pd.DataFrame(chart_data[alpha]).T[metric].to_dict())\n",
    "            plot = sns.boxplot(data = df, palette = \"ch:start=.2,rot=-.3\")\n",
    "            plot_title = \"Avg Clustering Ratio\" if metric == \"avg_clustering_ratio_obs\" else \"Modularity Communities Ratio\"\n",
    "            plt.pyplot.title(f\"Boxplot of {plot_title} for alpha = {round(alpha,3)}\")\n",
    "            plt.pyplot.ylim(0, 5)\n",
    "            plot.set_xticklabels(plot.get_xticklabels(), rotation=30)\n",
    "            #plt.pyplot.show()\n",
    "            name = f\"Boxplot of {plot_title} for alpha = {round(alpha,3)}.png\"\n",
    "            plt.pyplot.savefig(fname = name, bbox_inches = \"tight\")\n",
    "            plt.pyplot.close()\n",
    "\n",
    "#____________________________________________\n",
    "# DATAFRAMES CONSTRUCTOR FOR LINE PLOTS\n",
    "\n",
    "def distance_and_comparability_tables(chart_data, transformation):\n",
    "    alphas = list(chart_data.keys())\n",
    "    df_dist = pd.DataFrame(columns = alphas)\n",
    "    df_comp = pd.DataFrame(columns = alphas)\n",
    "    for alpha in chart_data:\n",
    "        distances = chart_data[alpha][transformation][\"edit_distance\"]\n",
    "        comparabilities = chart_data[alpha][transformation][\"comparability_measure\"]\n",
    "        df_dist[alpha] = distances\n",
    "        df_comp[alpha] = comparabilities\n",
    "\n",
    "    return df_dist.T, df_comp.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________\n",
    "# STATISTICS FUNCTION CALL\n",
    "\n",
    "# # loading the facebook dataset\n",
    "# df = pd.read_csv(\"facebookedgelist.csv\", delimiter=\";\")\n",
    "# df.columns = [\"source\", \"target\"]\n",
    "# facebook = nx.from_pandas_edgelist(df, \"source\", \"target\")\n",
    "\n",
    "# # loading the movies dataset\n",
    "# df = pd.read_csv(\"movies_edges.csv\")\n",
    "# df.columns = [\"source\", \"target\", \" \", \" \", \" \"]\n",
    "# movies = nx.from_pandas_edgelist(df, \"source\", \"target\")\n",
    "\n",
    "# generating Lancichinetti graph\n",
    "n = 250\n",
    "tau1 = 3\n",
    "tau2 = 1.5\n",
    "mu = 0.1\n",
    "Lancichinetti = nx.generators.community.LFR_benchmark_graph (n, tau1, tau2, mu, average_degree=2, min_community=17, seed=10)\n",
    "\n",
    "# generating gaussian random partition graph\n",
    "n = 100\n",
    "s = 10\n",
    "v = 10\n",
    "p_in = 0.4\n",
    "p_out = 0.1\n",
    "GRP = nx.generators.community.gaussian_random_partition_graph(n, s, v, p_in, p_out, seed = 42)\n",
    "\n",
    "# generating stochastic block model graph\n",
    "sizes = [75, 75, 125]\n",
    "probs = [[0.25, 0.05, 0.02], [0.05, 0.35, 0.07], [0.02, 0.07, 0.40]]\n",
    "SBM = nx.stochastic_block_model(sizes, probs, seed=0)\n",
    "\n",
    "# generating a windmill graph\n",
    "wg = nx.windmill_graph(7, 10)\n",
    "\n",
    "graphs = [\n",
    "    Lancichinetti,\n",
    "    GRP,\n",
    "    SBM,\n",
    "    wg\n",
    "    ]\n",
    "alpha_nums = np.linspace(0.1, 1, num=10)\n",
    "c_data, count = chart_data(graphs, alpha_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________\n",
    "# BOXPLOTS PRINT FUNCTION CALL\n",
    "\n",
    "sns.dark_palette(\"#69d\", reverse=True, as_cmap=True)\n",
    "boxplots(c_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e52b0b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#____________________________________________\n",
    "# PRINT OF EDIT DISTANCE AND COMPARABILITY MEASURE\n",
    "\n",
    "for transformation in TRANSFORMATIONS:\n",
    "    df_dist, df_comp = distance_and_comparability_tables(c_data, transformation)\n",
    "    df_dist[\"avg\"] = df_dist.mean(axis=1)\n",
    "    # plt.pyplot.plot(df_dist)\n",
    "    plt.pyplot.plot(df_dist[\"avg\"])\n",
    "    plt.pyplot.title(f\"Edit Distance: {transformation}\")\n",
    "    name = f\"Edit Distance {transformation}.png\"\n",
    "    plt.pyplot.savefig(fname = name, bbox_inches = \"tight\")\n",
    "    plt.pyplot.close()\n",
    "\n",
    "    df_comp[\"avg\"] = df_comp.mean(axis=1)\n",
    "    # plt.pyplot.plot(df_comp)\n",
    "    plt.pyplot.plot(df_comp[\"avg\"])\n",
    "    plt.pyplot.title(f\"Comparability measure: {transformation}\")\n",
    "    name = f\"Comparability measure {transformation}.png\"\n",
    "    plt.pyplot.savefig(fname = name, bbox_inches = \"tight\")\n",
    "    plt.pyplot.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
