{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01c55793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES\n",
    "import math\n",
    "import random\n",
    "import math\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib as plt\n",
    "import scipy as sp\n",
    "import scipy.sparse as sparse\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2a1b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deanon_ratio(G, H):\n",
    "    nx.write_weighted_edgelist(G, \"orig.edges\")\n",
    "    nx.write_weighted_edgelist(H, \"new.edges\")\n",
    "    n = len(G.nodes())\n",
    "    seed_nodes = random.sample(sorted(G.nodes()), int(round(0.05 * n)))\n",
    "    with open(\"seeds.txt\", \"w\") as s:\n",
    "        for sn in seed_nodes:\n",
    "            s.write(str(sn) + \" \" + str(sn) + \"\\n\")\n",
    "    cmd = \"java -jar secGraph.jar -m d -a DV -gA orig.edges \\\n",
    "        -gB new.edges -seed seeds.txt -bSize \" + str(n) + \" -nKeep \\\n",
    "        \" + str(n) + \" -gO out.txt -am stack\"\n",
    "    res = sproc.check_output(cmd, shell=True)\n",
    "    sval = res.split(\" \")[2].split(\"/\")\n",
    "    return float(sval[0])/float(sval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef3d2076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGF\n",
    "\n",
    "def SGF(G, transformation = \"modularity\", alpha = 0.8, normalization_type = \"truncate\", k = 6):\n",
    "\n",
    "    #____________________________________________\n",
    "    # INPUT MATRIX\n",
    "\n",
    "    # Setting up basic parameters\n",
    "    A = nx.adjacency_matrix(G).toarray()\n",
    "    n = len(A)\n",
    "    degrees = [G.degree[node] for node in G.nodes()]\n",
    "    M = np.zeros((n, n))\n",
    "\n",
    "    # identity transformation\n",
    "    if transformation == \"identity\":\n",
    "        M = A\n",
    "\n",
    "    # modularity transformation\n",
    "    elif transformation == \"modularity\":\n",
    "        m = sum(degrees) / 2\n",
    "        B = A - np.outer(degrees, degrees) / (2 * m)\n",
    "        M = B\n",
    "\n",
    "    # laplacian transformation\n",
    "    elif transformation == \"laplacian\":\n",
    "        D = np.diag(degrees)\n",
    "        L = D - A\n",
    "        M = L\n",
    "\n",
    "    # signless laplacian transformation\n",
    "    elif transformation == \"signless laplacian\":\n",
    "        D = np.diag(degrees)\n",
    "        L = D + A\n",
    "        M = L\n",
    "    \n",
    "    # General Zagreb transformation\n",
    "    elif transformation == \"General Zagreb\":\n",
    "        D = np.diag(degrees)\n",
    "        L = pow(D,3) + A\n",
    "        M = L\n",
    "\n",
    "    # Seidel transformation\n",
    "    elif transformation == \"Seidel\":\n",
    "        A_complement = np.ones((n, n)) - A - np.eye(n)\n",
    "        S = A - A_complement\n",
    "        M = S\n",
    "\n",
    "    # Sum connectivity transformation\n",
    "    elif transformation == \"Sum connectivity\":\n",
    "        SC = np.zeros((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if A[i][j] == 1:\n",
    "                    SC[i][j] = A[i][j] * (1 / math.sqrt((degrees[i] * degrees[j])))\n",
    "        M = SC\n",
    "\n",
    "    # Transition Random Walk transformation\n",
    "    elif transformation == \"Transition RW\":\n",
    "        D = np.diag(degrees)\n",
    "        P = np.linalg.inv(D) @ A\n",
    "        M = P\n",
    "\n",
    "    # Bethe-Hessian transformation\n",
    "    elif transformation == \"Bethe-Hessian\":\n",
    "        # Computing the non-backtracking matrix\n",
    "        Gdirect = G.to_directed()\n",
    "        S = np.zeros((len(Gdirect.edges),len(G.nodes)))\n",
    "        T = np.zeros((len(G.nodes),len(Gdirect.edges)))\n",
    "        for i,a in enumerate(Gdirect.edges):\n",
    "            for j,b in enumerate(G.nodes):\n",
    "                if a [ 1 ] == b:\n",
    "                    S[i,j]=1\n",
    "                if a [ 0 ] == b :\n",
    "                    T[j,i] = 1\n",
    "        tau = np.zeros((len(Gdirect.edges),len(Gdirect.edges)))\n",
    "        for i,a in enumerate(Gdirect.edges):\n",
    "            for j,b in enumerate(Gdirect.edges):\n",
    "                if a[0]==b[1] and a[1]==b[0]:\n",
    "                    tau[i][j] = 1\n",
    "        B = S@T - tau\n",
    "\n",
    "        # Computing the Bethe-Hessian matrix\n",
    "        D = np.diag(degrees)\n",
    "        I = np.eye(n, n)\n",
    "        rho = max(abs(np.linalg.eigvals(B)))\n",
    "        r = pow(rho, 1/2)\n",
    "        H = (pow(r,2) - 1) * I - r * A + D\n",
    "        M = H\n",
    "\n",
    "    #____________________________________________\n",
    "    # LOW RANK ALPHA APPROXIMATION\n",
    "    \n",
    "    # Computation of eigenvalues and eigenvectors\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(M)\n",
    "    eigenvectors = eigenvectors.T\n",
    "\n",
    "    # sorting the eigenvectors, eigenvalues\n",
    "    paired_sorted_list = sorted(zip(eigenvalues, eigenvectors), key=lambda x: x[0])\n",
    "    eigenvalues_sorted, eigenvectors_sorted = zip(*paired_sorted_list)\n",
    "\n",
    "    # Computation of M_tilde\n",
    "    M_tilde = np.zeros((eigenvectors_sorted[0].shape[0], eigenvectors_sorted[0].shape[0]))\n",
    "    for i in range(math.ceil(alpha * len(eigenvalues))):\n",
    "        contribution = eigenvalues_sorted[i] * np.outer(eigenvectors_sorted[i], eigenvectors_sorted[i])\n",
    "        M_tilde += contribution\n",
    "\n",
    "    #____________________________________________\n",
    "    # BACK TRANSFORMATION\n",
    "        \n",
    "    # Computation of A_tilde\n",
    "    A_tilde = np.zeros((n, n))\n",
    "    if transformation == \"identity\":\n",
    "        A_tilde = M_tilde\n",
    "    elif transformation == \"modularity\":\n",
    "        A_tilde = M_tilde + np.outer(degrees, degrees) / (2 * m)\n",
    "    elif transformation == \"laplacian\":\n",
    "        A_tilde = D - M_tilde\n",
    "    elif transformation == \"signless laplacian\":\n",
    "        A_tilde = M_tilde - D\n",
    "    elif transformation == \"General Zagreb\":\n",
    "        A_tilde = M_tilde - pow(D,3)\n",
    "    elif transformation == \"Seidel\":\n",
    "        A_tilde = M_tilde + A_complement\n",
    "    elif transformation == \"Sum connectivity\":\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if A[i][j] == 1:\n",
    "                    A_tilde[i][j] = M_tilde[i][j] * math.sqrt((degrees[i] * degrees[j]))\n",
    "    elif transformation == \"Transition RW\":\n",
    "        A_tilde = D @ M_tilde\n",
    "    elif transformation == \"Bethe-Hessian\":\n",
    "        A_tilde = ((r**2 - 1) * I - M_tilde + D) * (1 / r)\n",
    "\n",
    "    #____________________________________________\n",
    "    # NORMALIZATION\n",
    "\n",
    "    # logistic\n",
    "    A_dots = np.zeros((n, n))\n",
    "    if normalization_type == \"logistic\":\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                A_dots[i][j] = 1 / (1 + math.exp((0.5 - A_tilde[i][j])*k))\n",
    "\n",
    "    # truncation\n",
    "    elif normalization_type == \"truncate\":\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if A_tilde[i][j] < 0:\n",
    "                    A_dots[i][j] = 0\n",
    "                elif A_tilde[i][j] > 1:\n",
    "                    A_dots[i][j] = 1\n",
    "                else:\n",
    "                    A_dots[i][j] = A_tilde[i][j]\n",
    "\n",
    "    # scaling\n",
    "    elif normalization_type == \"scale\":\n",
    "        A_tilde_flattened = A_tilde.flatten()\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                A_dots[i][j] = (A_tilde[i][j] - min(A_tilde_flattened)) / (max(A_tilde_flattened) - min(A_tilde_flattened))\n",
    "    \n",
    "    #____________________________________________\n",
    "    # ADJACENCY MATRIX GENERATION\n",
    "    \n",
    "    # Bernoulli sampling\n",
    "    A_prime = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            u = random.uniform(0, 1)\n",
    "            if u < A_dots[i][j]:\n",
    "                A_prime[i][j] = 1\n",
    "                A_prime[j][i] = 1\n",
    "            else:\n",
    "                A_prime[i][j] = 0\n",
    "                A_prime[j][i] = 0\n",
    "            if i == j:\n",
    "                A_prime[i][j] = 0\n",
    "\n",
    "    W = nx.from_numpy_array(A_prime)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cf45b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph with 99 nodes and 317 edges\n",
      "Graph with 99 nodes and 389 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: Unable to access jarfile secGraph.jar\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'java -jar secGraph.jar -m d -a DV -gA orig.edges         -gB new.edges -seed seeds.txt -bSize 99 -nKeep         99 -gO out.txt -am stack' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(W)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#nx.draw_kamada_kawai(W)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m deanon_ratio \u001b[38;5;241m=\u001b[39m \u001b[43mdeanon_ratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmovies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(deanon_ratio)\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mdeanon_ratio\u001b[0;34m(G, H)\u001b[0m\n\u001b[1;32m      8\u001b[0m         s\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28mstr\u001b[39m(sn) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(sn) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjava -jar secGraph.jar -m d -a DV -gA orig.edges \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m    -gB new.edges -seed seeds.txt -bSize \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(n) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -nKeep \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(n) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m -gO out.txt -am stack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m sval \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(sval[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mfloat\u001b[39m(sval[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:466\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    464\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[0;32m--> 466\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m           \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'java -jar secGraph.jar -m d -a DV -gA orig.edges         -gB new.edges -seed seeds.txt -bSize 99 -nKeep         99 -gO out.txt -am stack' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# TEST - MOVIE GRAPH\n",
    "\n",
    "df = pd.read_csv(\"movies_edges.csv\", delimiter=\",\")\n",
    "df.columns = [\"source\", \"target\",\"label\", \"movie_id\", \"weight\"]\n",
    "movies = nx.from_pandas_edgelist(df, \"source\", \"target\")\n",
    "\n",
    "print(movies)\n",
    "#nx.draw_kamada_kawai(movies)\n",
    "#plt.pyplot.show()\n",
    "\n",
    "W = SGF(movies, transformation = \"modularity\", alpha = 0.9, normalization_type = \"truncate\", k = 6)\n",
    "\n",
    "print(W)\n",
    "#nx.draw_kamada_kawai(W)\n",
    "deanon_ratio = deanon_ratio(movies, W)\n",
    "print(deanon_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2999ac16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS COMPUTATION (LONG TO RUN)\n",
    "\n",
    "def statistics(graphs, sample_size = 100):\n",
    "\n",
    "    #____________________________________________\n",
    "    # GRAPH STATISTICS\n",
    "    alpha_dict = {}\n",
    "    for alpha in tqdm([0.5, 0.7, 0.9]):\n",
    "        g_dict = {\n",
    "            \"transformation\": [],\n",
    "            \"g_name\": [],\n",
    "            \"avg_clustering_ratio_obs\":[],\n",
    "            \"modularity_communities_ratio_obs\":[],\n",
    "            \"De-anonymization ratio\":[]\n",
    "        }\n",
    "        for name, g in graphs:\n",
    "            g_avg_clustering = nx.average_clustering(g)\n",
    "            g_modularity = nx.community.greedy_modularity_communities(g)\n",
    "            \n",
    "            for transformation in tqdm([\"identity\", \"modularity\", \"laplacian\", \"Bethe-Hessian\"]):\n",
    "                for i in range(sample_size):\n",
    "                    w = SGF(g, transformation, alpha)\n",
    "                    g_dict[\"transformation\"].append(transformation)\n",
    "                    g_dict[\"g_name\"].append(name)\n",
    "                    g_dict[\"avg_clustering_ratio_obs\"].append(nx.average_clustering(w)/ g_avg_clustering)\n",
    "                    g_dict[\"modularity_communities_ratio_obs\"].append(len(nx.community.greedy_modularity_communities(w))/ len(g_modularity))\n",
    "                    g_dict[\"De-anonymization ratio\"].append(deanon_ratio(g,w))\n",
    "        alpha_dict[alpha]  = pd.DataFrame(g_dict)\n",
    "    return alpha_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae0bdf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.05it/s]\n",
      "100%|██████████| 4/4 [04:30<00:00, 67.71s/it]\n",
      " 50%|█████     | 2/4 [15:06:52<15:06:52, 27206.16s/it]\n",
      "  0%|          | 0/3 [15:11:27<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# creating graphs list\u001b[39;00m\n\u001b[1;32m      8\u001b[0m graphs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkarate\u001b[39m\u001b[38;5;124m\"\u001b[39m, nx\u001b[38;5;241m.\u001b[39mkarate_club_graph()),\n\u001b[1;32m     10\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLFR\u001b[39m\u001b[38;5;124m\"\u001b[39m, nx\u001b[38;5;241m.\u001b[39mLFR_benchmark_graph(\u001b[38;5;241m300\u001b[39m,\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1.5\u001b[39m, \u001b[38;5;241m1\u001b[39m, min_degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m     11\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindill\u001b[39m\u001b[38;5;124m\"\u001b[39m, nx\u001b[38;5;241m.\u001b[39mwindmill_graph(\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m6\u001b[39m)),\n\u001b[1;32m     12\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacebook\u001b[39m\u001b[38;5;124m\"\u001b[39m, facebook),\n\u001b[1;32m     13\u001b[0m ]\n\u001b[0;32m---> 14\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mstatistics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 29\u001b[0m, in \u001b[0;36mstatistics\u001b[0;34m(graphs, sample_size)\u001b[0m\n\u001b[1;32m     27\u001b[0m         g_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(name)\n\u001b[1;32m     28\u001b[0m         g_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_clustering_ratio_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(nx\u001b[38;5;241m.\u001b[39maverage_clustering(w)\u001b[38;5;241m/\u001b[39m g_avg_clustering)\n\u001b[0;32m---> 29\u001b[0m         g_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodularity_communities_ratio_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(\u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_modularity_communities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(g_modularity))\n\u001b[1;32m     30\u001b[0m         g_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDe-anonymization ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(deanonymization_ratio(g,w))\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# stats_dict = {\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m#     \"avg_clustering_ratio_obs\": average_clustering_ratio_obs,\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m#     \"modularity_communities_ratio_obs\": modularity_communities_ratio_obs\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# transformation_dict[transformation] = stats_dict\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# g_dict[name] = transformation_dict\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/networkx/utils/backends.py:412\u001b[0m, in \u001b[0;36m_dispatch.__call__\u001b[0;34m(self, backend, *args, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m backends:\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;66;03m# Fast path if no backends are installed\u001b[39;00m\n\u001b[0;32m--> 412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morig_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# Use `backend_name` in this function instead of `backend`\u001b[39;00m\n\u001b[1;32m    415\u001b[0m     backend_name \u001b[38;5;241m=\u001b[39m backend\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/networkx/algorithms/community/modularity_max.py:349\u001b[0m, in \u001b[0;36mgreedy_modularity_communities\u001b[0;34m(G, weight, resolution, cutoff, best_n)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dq \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(communities) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m best_n:\n\u001b[1;32m    348\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m     communities \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(community_gen)\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(communities, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/networkx/algorithms/community/modularity_max.py:176\u001b[0m, in \u001b[0;36m_greedy_modularity_communities_generator\u001b[0;34m(G, weight, resolution)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;66;03m# Save old value for finding heap index\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m v_nbrs:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Update existing element in per-row heap\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[43mdq_heap_row\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpriority\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_negdq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# We're creating a new nonzero element, add to heap\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     dq_heap_row\u001b[38;5;241m.\u001b[39mpush(d, priority\u001b[38;5;241m=\u001b[39md_negdq)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/networkx/utils/mapped_queue.py:213\u001b[0m, in \u001b[0;36mMappedQueue.update\u001b[0;34m(self, elt, new, priority)\u001b[0m\n\u001b[1;32m    211\u001b[0m     new \u001b[38;5;241m=\u001b[39m _HeapElement(priority, new)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Replace\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m[\u001b[49m\u001b[43melt\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheap[pos] \u001b[38;5;241m=\u001b[39m new\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition[elt]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/networkx/utils/mapped_queue.py:69\u001b[0m, in \u001b[0;36m_HeapElement.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     65\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using a tuple, with a priority value that can be compared.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m             )\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpriority \u001b[38;5;241m>\u001b[39m other_priority\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melement \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39melement\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CALL STATISTICS FUNCTION\n",
    "\n",
    "df = pd.read_csv(\"facebookedgelist.csv\", delimiter=\";\")\n",
    "df.columns = [\"source\", \"target\"]\n",
    "facebook = nx.from_pandas_edgelist(df, \"source\", \"target\")\n",
    "\n",
    "# creating graphs list\n",
    "graphs = [\n",
    "    (\"karate\", nx.karate_club_graph()),\n",
    "    (\"LFR\", nx.LFR_benchmark_graph(300, 3, 1.5, 1, min_degree = 2)),\n",
    "    (\"windill\", nx.windmill_graph(300, 6)),\n",
    "    (\"facebook\", facebook),\n",
    "]\n",
    "data = statistics(graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f425ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m sns\u001b[38;5;241m.\u001b[39mset_theme(style\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mticks\u001b[39m\u001b[38;5;124m\"\u001b[39m, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpastel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m alpha \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m:\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Draw a nested boxplot to show bills by day and time\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m data[alpha]\n\u001b[1;32m      6\u001b[0m     sns\u001b[38;5;241m.\u001b[39mboxplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_clustering_ratio_obs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m                 hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformation\u001b[39m\u001b[38;5;124m\"\u001b[39m, palette\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m                 data\u001b[38;5;241m=\u001b[39mdf)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "for alpha in data:\n",
    "# Draw a nested boxplot to show bills by day and time\n",
    "    df = data[alpha]\n",
    "    sns.boxplot(x=\"g_name\", y=\"avg_clustering_ratio_obs\",\n",
    "                hue=\"transformation\", palette=[\"m\", \"g\", \"b\", \"r\"],\n",
    "                data=df)\n",
    "    sns.despine(offset=10, trim=True)\n",
    "\n",
    "    plt.pyplot.show()\n",
    "    # Draw a nested boxplot to show bills by day and time\n",
    "    sns.boxplot(x=\"g_name\", y=\"modularity_communities_ratio_obs\",\n",
    "                hue=\"transformation\", palette=[\"m\", \"g\", \"b\", \"r\"],\n",
    "                data=df)\n",
    "    sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efe87dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT STATISTICS IN BOXPLOTS\n",
    "\n",
    "sns.set_theme(style=\"ticks\", palette=\"pastel\")\n",
    "tips = {\n",
    "    'total_bill': [16.99, 10.34, 21.01, 23.68, 24.59],\n",
    "    'tip': [1.01, 1.66, 3.50, 3.31, 3.61],\n",
    "    'sex': ['Female', 'Male', 'Male', 'Male', 'Female'],\n",
    "    'smoker': ['No', 'Yes', 'No', 'No', 'Yes'],\n",
    "    'day': ['Sun', 'Sun', 'Mon', 'Mon', 'Sun'],\n",
    "    'time': ['Lunch', 'Dinner', 'Dinner', 'Dinner', 'Dinner'],\n",
    "    'size': [2, 3, 3, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(tips)\n",
    "\n",
    "\n",
    "\n",
    "# Load the example tips dataset\n",
    "\n",
    "# Draw a nested boxplot to show bills by day and time\n",
    "sns.boxplot(x=\"day\", y=\"total_bill\",\n",
    "            hue=\"smoker\", palette=[\"m\", \"g\"],\n",
    "            data=tips)\n",
    "sns.despine(offset=10, trim=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
